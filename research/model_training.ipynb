{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainingConfig:\n",
    "    root_dir:Path\n",
    "    data_dir:Path\n",
    "    best_model:Path\n",
    "    split_dir:Path\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Loan_defaulter.constants import *\n",
    "from src.Loan_defaulter.utils.common import read_yaml,create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_filepath=CONFIG_FILE_PATH,\n",
    "            params_filepath=PARAMS_FILE_PATH\n",
    "\n",
    "    ):\n",
    "        self.config=read_yaml(config_filepath)\n",
    "        self.params=read_yaml(params_filepath)\n",
    "        \n",
    "\n",
    "    def get_data_training_config(self)->ModelTrainingConfig:\n",
    "        config=self.config\n",
    "       \n",
    "        create_directories([config.model_training.root_dir])\n",
    "\n",
    "        data_transformation_config=ModelTrainingConfig(\n",
    "            root_dir=config.model_training.root_dir,\n",
    "            split_dir=config.data_transformation.split_dir,\n",
    "            data_dir=config.data_ingestion.data_dir,\n",
    "            best_model=config.model_training.best_model,\n",
    "            \n",
    "        )\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from src.Loan_defaulter.utils.common import load_object,evaluate_models,save_object\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self,config:ModelTrainingConfig):\n",
    "        self.config = config\n",
    "    def load_datasets(self):\n",
    "        self.training_data=load_object(os.path.join(self.config.split_dir,'train.pkl'))\n",
    "        self.testing_data=load_object(os.path.join(self.config.split_dir,'test.pkl'))\n",
    "        self.val_data=load_object(os.path.join(self.config.split_dir,'val.pkl'))\n",
    "    def training(self):\n",
    "        X_train,y_train,X_test,y_test,X_val,y_val=(\n",
    "            self.training_data[:,:-1],self.training_data[:,-1],\n",
    "            self.testing_data[:,:-1],self.testing_data[:,-1],\n",
    "            self.val_data[:,:-1],self.val_data[:,-1]\n",
    "\n",
    "        )\n",
    "        \n",
    "\n",
    "        classes = np.unique(y_train)\n",
    "        class_weights = compute_class_weight('balanced', classes=classes, y=y_train)\n",
    "        class_weight_dict = dict(zip(classes, class_weights))\n",
    "        negative_samples = sum(y_train == 0)\n",
    "        positive_samples = sum(y_train == 1)\n",
    "        scale_pos_weight = negative_samples / positive_samples\n",
    "\n",
    "# Use scale_pos_weight in the model\n",
    "\n",
    "        models={\n",
    "            'BalancedKNN':BalancedBaggingClassifier(estimator=KNeighborsClassifier(n_jobs=-1),random_state=42),\n",
    "            'BalancedLogistic':BalancedBaggingClassifier(estimator=LogisticRegression(n_jobs=-1)),\n",
    "            'BalancedRandomForest':BalancedRandomForestClassifier(n_jobs=-1),\n",
    "            'LogisticRegression':LogisticRegression(class_weight=class_weight_dict,n_jobs=-1),\n",
    "            'XGC':XGBClassifier(scale_pos_weight=scale_pos_weight),\n",
    "            'DT':DecisionTreeClassifier(class_weight=class_weight_dict),\n",
    "            'RandomForestClassifier':RandomForestClassifier(class_weight=class_weight_dict)\n",
    "        }\n",
    "# Evaluate models\n",
    "        model_report = evaluate_models(X=X_train, y=y_train, models=models, X_test=X_test, y_test=y_test)\n",
    "\n",
    "        # Sort the models based on the highest metric value\n",
    "        sorted_models = dict(sorted(model_report.items(), key=lambda item: max(item[1]), reverse=True))\n",
    "\n",
    "        # Filter out overfitting models (assuming overfitting means a perfect score of 1 on training)\n",
    "        non_overfit_models = {\n",
    "            model: metrics for model, metrics in model_report.items() if metrics[0] != 1 and metrics[1] != 1\n",
    "        }\n",
    "\n",
    "        # Get the best non-overfitting model (sorted by the maximum metric value)\n",
    "        best_model_name, best_model_metrics = sorted(non_overfit_models.items(), key=lambda item: max(item[1]), reverse=True)[0]\n",
    "\n",
    "        # Output the best model's name and metrics\n",
    "        print(f\"Best Model: {best_model_name}\")\n",
    "        print(f\"Metrics: {best_model_metrics}\")\n",
    "        best_model=models[best_model_name]\n",
    "        save_object(self.config.best_model,obj=best_model)\n",
    "        print('recall',best_model_metrics[0],'precision',best_model_metrics[1])\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-28 21:07:14,126:INFO:common:yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-12-28 21:07:14,127:INFO:common:yaml file: params.yaml loaded successfully]\n",
      "[2024-12-28 21:07:14,129:INFO:common:created directory at: artifacts/model_training]\n",
      "Best Model: BalancedKNN\n",
      "Metrics: [0.7179593529655744, 0.9521452145214522]\n",
      "recall 0.7179593529655744 precision 0.9521452145214522\n"
     ]
    }
   ],
   "source": [
    "config=ConfigurationManager()\n",
    "training_config=config.get_data_training_config()\n",
    "train=ModelTrainer(config=training_config)\n",
    "train.load_datasets()\n",
    "train.training()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State: 42\n"
     ]
    }
   ],
   "source": [
    "print(\"Random State:\", model.random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
